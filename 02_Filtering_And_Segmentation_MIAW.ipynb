{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Analysis workshop - IT-IST\n",
    "## Image Filtering (edge preserving denoising, smoothing, etc.), Resampling and Segmentation\n",
    "\n",
    "Lets load the image saved in previous notebook and view it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import itk\n",
    "import itkwidgets as itkw\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0237b4a6d341da8e2b9125e1fd89af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='x', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_itk = itk.imread('./cT1wNeuro.nrrd')\n",
    "\n",
    "image_sitk = sitk.ReadImage('./cT1wNeuro.nrrd')\n",
    "itkw.view(image_itk, cmap='Grayscale', mode='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "\n",
    "### Curvature Anisotropic Diffusion Filter\n",
    "The Curvature Anisotropic Diffusion Filter ([Documentation SimpleITK](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1CurvatureAnisotropicDiffusionImageFilter.html)) is widely used in medical images to denoise your image while preserving the edges. \n",
    "\n",
    "Note 1: ITK/SimpleITK often poses restriction into the pixel/voxel type to execute some operations. In this case we can use the Cast Image filter to convert our image of type short into float. Be careful when performing the cast operation from higher to lower pixel/voxel types (rescaling may be required)\n",
    "\n",
    "Note 2: There are several types of Anisotropic Diffusion Filters and another commonly used is the Gradient Anisotropic Diffusion filter (an example of that may be found on the Extras notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sitk_float = sitk.Cast(image_sitk, sitk.sitkFloat32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006f654c584848c3812d3d0e2f003c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='x', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smooth_cadf_sitk = sitk.CurvatureAnisotropicDiffusion(image_sitk_float)\n",
    "itkw.view(smooth_cadf_sitk, cmap='Grayscale', mode='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, ITK is more verbose than SimpleITK but it more customizable and offers additional filters.\n",
    "\n",
    "The same result that was achieved by with three lines requires the following in ITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "castImageFilter = itk.CastImageFilter[image_itk, itk.Image[itk.F,3]].New(image_itk)\n",
    "castImageFilter.Update()\n",
    "image_itk_float = castImageFilter.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d5145625c949139f153ab9b487fd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='x', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curv_ani_dif_filter = itk.CurvatureAnisotropicDiffusionImageFilter[image_itk_float, itk.Image[itk.F,3]].New(image_itk_float)\n",
    "curv_ani_dif_filter.Update()\n",
    "\n",
    "smooth_cadf = curv_ani_dif_filter.GetOutput()\n",
    "itkw.view(smooth_cadf, cmap='Grayscale', mode='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Filter \n",
    "[Documentation SimpleITK](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1MedianImageFilter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7436f3d41c240b9bfdb8b2de4674953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='x', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# median_filter = sitk.MedianImageFilter()\n",
    "# median_filter.SetRadius(2) # In pixels/voxels\n",
    "# median_image = median_filter.Execute(image_sitk_float)\n",
    "\n",
    "median_image = sitk.Median(image_sitk_float, [2, 2, 2])\n",
    "\n",
    "itkw.view(median_image, cmap='Grayscale', mode='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel Filter \n",
    "[Documentation SimpleITK](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1SobelEdgeDetectionImageFilter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b3bef7b2644b668ea7aaaa81939cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='x', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sobel_edge_image = sitk.SobelEdgeDetection(image_sitk_float)\n",
    "itkw.view(sobel_edge_image, cmap='Grayscale', mode='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Sharpening Image Filter\n",
    "[Documentation SimpleITK](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1LaplacianSharpeningImageFilter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867230b64291410c90c86cd9b97451c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='x', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "laplacian_sharped_image = sitk.LaplacianSharpening(image_sitk_float)\n",
    "itkw.view(laplacian_sharped_image, cmap='Grayscale', mode='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also compare two images using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c24ea7ce6394383adc9db6e4fcf5df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Viewer(annotations=False, cmap='Grayscale', interpolation=False, mode='x', rendered_image=<itkI…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "itkw.checkerboard(median_image, laplacian_sharped_image, cmap='Grayscale', mode='x', pattern=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling an Image\n",
    "\n",
    "This image is isotropic with voxels of size 1mm x 1mm x 1mm. Often images come with different voxel sizes, and depending on the analysis we may have to normalize the voxel size accross the dataset. \n",
    "\n",
    "So lets learn how to change the voxel spacing/size from 1mm x 1mm x 1mm to 1.5mm x 2mm x 3mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resample image spacing: [1.5, 2.0, 5.0]\n",
      "Resample image size: [171, 128, 36]\n",
      "Original image spacing: [1.0, 1.0, 1.0]\n",
      "Original image size: [256, 256, 176]\n"
     ]
    }
   ],
   "source": [
    "resample = sitk.ResampleImageFilter()\n",
    "resample.SetInterpolator = sitk.sitkBSpline\n",
    "resample.SetOutputDirection(image_sitk_float.GetDirection())\n",
    "resample.SetOutputOrigin(image_sitk_float.GetOrigin())\n",
    "new_spacing = [1.5, 2, 5]\n",
    "resample.SetOutputSpacing(new_spacing)\n",
    "\n",
    "orig_size = np.array(image_sitk_float.GetSize(), dtype=np.int)\n",
    "orig_spacing = np.array(image_sitk_float.GetSpacing(), dtype=np.float)\n",
    "new_size = orig_size * (orig_spacing / new_spacing)\n",
    "new_size = np.ceil(new_size).astype(np.int)  # Image dimensions are in integers\n",
    "new_size = [int(s) for s in new_size]\n",
    "resample.SetSize(new_size)\n",
    "\n",
    "resampled_image = resample.Execute(image_sitk_float)\n",
    "\n",
    "print('Resample image spacing:', list(resampled_image.GetSpacing()))\n",
    "print('Resample image size:', list(resampled_image.GetSize()))\n",
    "print('Original image spacing:', list(image_sitk_float.GetSpacing()))\n",
    "print('Original image size:', list(image_sitk_float.GetSize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Filters\n",
    "\n",
    "Another common task on the medical image domain is the segmentation.\n",
    "\n",
    "In this example we will work with a different image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e09099e4554d9bb393c3986a8a5b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_brainT1 = sitk.ReadImage('./brain_T1.nii.gz')\n",
    "image_brainT1_mask_float = sitk.ReadImage('./brain_T1_mask.nii.gz')\n",
    "# it is possible to force reading an image with a specific pixel/voxel type\n",
    "image_brainT1_mask_uc = sitk.ReadImage('./brain_T1_mask.nii.gz', sitk.sitkUInt8)\n",
    "\n",
    "itkw.view(image_brainT1, cmap='Grayscale', mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to observe that for this case we also have a binary mask corresponding to the brain.\n",
    "\n",
    "Using the multiply filter we can obtain an image with just the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf29fed993946ecb6c09e4a27efa8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brain_image = sitk.Multiply(image_brainT1, image_brainT1_mask_float)# image_atlas * image_atlas_mask\n",
    "itkw.view(brain_image, cmap='Grayscale', mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: show multiplication by using *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Threshold with lower and upper threshold\n",
    "[Documentation SimpleITK](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1BinaryThresholdImageFilter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e52d6aa164463799a70fbc02f14711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binary_mask = sitk.BinaryThreshold(brain_image, lowerThreshold=300, upperThreshold=600, insideValue=1, outsideValue=0)\n",
    "itkw.view(binary_mask, cmap='Grayscale', mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactively discretize your image using Otsu Multiple Threshold method\n",
    "[Documentation SimpleITK](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1OtsuMultipleThresholdsImageFilter.html)\n",
    "\n",
    "In this example you can see how to use SimpleITK and ipywidgets interactively change parameters of a filter (Otsu Multiple Thresholds) and check the results immediately!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1675a7c1804aeb8be90700ecee6ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Viewer(annotations=False, cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', poi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "viewer_int = itkw.view(brain_image, cmap='Grayscale', mode='z', annotations=False)\n",
    "\n",
    "# Create an itk smoother filter object. By re-using the object, output memory-reallocation is avoided\n",
    "otsu_filter = sitk.OtsuMultipleThresholdsImageFilter() # [brain_image, itk.Image[itk.F,3]].New(brain_image)\n",
    "otsu_filter.SetNumberOfHistogramBins(64)\n",
    "\n",
    "def otsu_and_view(thresholds=2):\n",
    "    otsu_filter.SetNumberOfThresholds(thresholds)\n",
    "    # Execute and Update the image used in the viewer\n",
    "    viewer_int.image = otsu_filter.Execute(brain_image)\n",
    "slider = interactive(otsu_and_view, thresholds=(1, 5, 1))\n",
    "\n",
    "widgets.VBox([viewer_int, slider])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region Growing Filters\n",
    "[Documentation SimpleITK](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1ConfidenceConnectedImageFilter.html)\n",
    "\n",
    "These are a type filters that require a seed point to perform the segmentation. We will try to segment the white matter using the Confidence Connected algorithm but other implementations like the Connected Threshold and the Neighborhood Connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80d484778fb41328dff6388cba2047f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confidence_connected_filter = sitk.ConfidenceConnectedImageFilter()\n",
    "confidence_connected_filter.SetMultiplier(1.80)\n",
    "confidence_connected_filter.SetSeed([30, 61, 77])\n",
    "confidence_connected_filter.SetNumberOfIterations( 10 );\n",
    "confidence_connected_filter.SetReplaceValue( 255 );\n",
    "confidence_connected_filter.SetInitialNeighborhoodRadius( 3 );\n",
    "white_matter_image = confidence_connected_filter.Execute(brain_image)\n",
    "\n",
    "itkw.view(white_matter_image, cmap='Grayscale', mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segmentation is far from perfect. If we go back to the image, it is possible to observe that this MRI image was affected by bias field inhomogeneity. This artifact affects the performance of segmentation filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering MRI bias field inhomogeneity\n",
    "\n",
    "<img src=\"bias_field_example.jpeg\"> [Image Source](http://digitool.library.mcgill.ca/webclient/StreamGate?folder_id=0&dvs=1579874409466~728)\n",
    "\n",
    "### N4 Bias Field Correction Image Filter\n",
    "\n",
    "[Documentation SimpleITK](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1N4BiasFieldCorrectionImageFilter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71249cec0ca4313bf8951fbe9fbf3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Viewer(annotations=False, cmap='Grayscale', interpolation=False, mode='z', rendered_image=<itkI…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bias_field_filter = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "bias_field_filter.SetNumberOfControlPoints([4,4,4])\n",
    "bias_corrected_image = bias_field_filter.Execute(sitk.Cast(brain_image,sitk.sitkFloat32), image_brainT1_mask_uc)\n",
    "\n",
    "itkw.checkerboard(bias_corrected_image, brain_image, cmap='Grayscale', mode='z', pattern=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now try to segment the white matter again using the same filter and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f75e51c0da450aaa232810518be4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confidence_connected_filter = sitk.ConfidenceConnectedImageFilter()\n",
    "# confidence_connected_filter.SetInput(bias_corrected_image)\n",
    "confidence_connected_filter.SetSeed([30, 61, 77])\n",
    "confidence_connected_filter.SetMultiplier( 1.80 );\n",
    "confidence_connected_filter.SetNumberOfIterations( 10 );\n",
    "confidence_connected_filter.SetReplaceValue( 255 );\n",
    "confidence_connected_filter.SetInitialNeighborhoodRadius( 3 );\n",
    "white_matter_mask = confidence_connected_filter.Execute(bias_corrected_image)\n",
    "\n",
    "itkw.view(white_matter_mask, cmap='Grayscale', mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkboard of Brain Image <-> White Matter Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2312ee16f45349f099e468fd7e609651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Viewer(annotations=False, cmap='Grayscale', interpolation=False, mode='z', rendered_image=<itkI…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "white_matter_mask_float = sitk.Cast(white_matter_mask, sitk.sitkFloat32) * 5 ## * 5 -> bring the mask to an intensity ~ of the image\n",
    "itkw.checkerboard(white_matter_mask_float, image_brainT1, cmap='Grayscale', mode='z', pattern=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced Segmentation Filters\n",
    "### Bayesian Classifier Image Filter Segmentation\n",
    "\n",
    "This filter\n",
    "\n",
    "This filter does not exist in SimpleITK, only in ITK. Using the numpy (python scientific computing package providing powerful N-dimensional array object) interface of both libraries we will recreate the bias field corrected simple itk images as an itk image.\n",
    "\n",
    "The conversion of SimpleITK image to and ITK image will be your first exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise #1\n",
    "\n",
    "Convert the bias_corrected_image, which is a SimpleITK image object to ITK image object called bias_corrected_itk_image.\n",
    "\n",
    "##### Tips (functions required):\n",
    "- sitk.GetArrayFromImage() - converts the SimpleITK image into a numpy array (physical properties of image like spacing, origin and direction are lost)\n",
    "- itk.GetImageFromArray() - converts the numpy array into a SimpleITK image (physical properties of image like spacing, origin and direction are set to default values)\n",
    "- bias_corrected_image.GetOrigin() - get SimpleITK image world coordinates origin vector\n",
    "- bias_corrected_image.GetSpacing() - get SimpleITK image spacing vector\n",
    "- bias_corrected_image.GetDirection() - get SimpleITK image direction vector\n",
    "- bias_corrected_itk_image.SetOrigin(<vector_correct_origin>) - set the correct world coordinates origin using the values prodived in the vector\n",
    "- bias_corrected_itk_image.SetSpacing(<vector_correct_spacing>) - set the correct spacing using the values prodived in the vector\n",
    "\n",
    "- Set direction is a little bit trickier so here is the example of the code that you can use:\n",
    "```python\n",
    "# The interface for the direction is a little trickier\n",
    "np_dir_vnl = itk.vnl_matrix_from_array(np.array(original_direction).reshape(3,3))\n",
    "DirectionType = type(bias_corrected_itk_image.GetDirection())\n",
    "direction = DirectionType(np_dir_vnl)\n",
    "bias_corrected_itk_image.SetDirection(direction)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this code box to write your solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34512db646ae481487a1462752150a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bias_corrected_np_image = sitk.GetArrayFromImage(bias_corrected_image)\n",
    "original_spacing = bias_corrected_image.GetSpacing()\n",
    "original_origin = bias_corrected_image.GetOrigin()\n",
    "original_direction = bias_corrected_image.GetDirection()\n",
    "bias_corrected_itk_image = itk.GetImageFromArray(bias_corrected_np_image)\n",
    "bias_corrected_itk_image.SetSpacing(original_spacing)\n",
    "bias_corrected_itk_image.SetOrigin(original_origin)\n",
    "\n",
    "# The interface for the direction is a little trickier\n",
    "np_dir_vnl = itk.vnl_matrix_from_array(np.array(original_direction).reshape(3,3))\n",
    "DirectionType = type(bias_corrected_itk_image.GetDirection())\n",
    "direction = DirectionType(np_dir_vnl)\n",
    "bias_corrected_itk_image.SetDirection(direction)\n",
    "\n",
    "itkw.view(bias_corrected_itk_image, cmap='Grayscale', mode='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8588cd3d38148b98565a4a0f929b272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The goal of this filter is to generate a membership image that indicates the membership of each pixel to each class. \n",
    "# These membership images are fed as input to the Bayesian classifier filter.\n",
    "# BayesianClassifierInitializationImageFilter runs K-means on the image to determine k Gaussian density functions centered \n",
    "# around 'n' pixel intensity values. This is equivalent to generate Gaussian mixture model for the input image.\n",
    "instance = itk.BayesianClassifierInitializationImageFilter[bias_corrected_itk_image, itk.F].New(bias_corrected_itk_image)\n",
    "instance.SetNumberOfClasses(5)\n",
    "instance.Update()\n",
    "# The output to this filter is an itk::VectorImage that represents pixel memberships to 'n' classes. \n",
    "image_bayesian_class = instance.GetOutput() \n",
    "\n",
    "# Performs Bayesian Classification on an image using the membership Vector Image obtained by the itk.BayesianClassifierInitializationImageFilter.\n",
    "bc = itk.BayesianClassifierImageFilter[image_bayesian_class, itk.SS, itk.F, itk.F].New(image_bayesian_class)\n",
    "bc.Update()\n",
    "labelled_bayesian = bc.GetOutput()\n",
    "itkw.view(labelled_bayesian, cmap='Grayscale', mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Misture Models (GMMs) Segmentation\n",
    "\n",
    "To execute this we will make use of the interface ITK <-> numpy and use scikit-learn use Gaussian Mixture Models (GMMs) to perform the segmentation.\n",
    "\n",
    "We will start by getting some statistics of the image using the segmentation labels.\n",
    "\n",
    "These will be used in the GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb4522657a3409f86dd5a1313e10f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(cmap='Grayscale', geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkIma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Copy of itk.Image to numpy.ndarray\n",
    "np_copy = itk.array_from_image(bias_corrected_itk_image)\n",
    "np_mask_copy = itk.array_from_image(labelled_bayesian)\n",
    "middle_slice = int(np.floor(np_copy.shape[0]/2))\n",
    "gmm = GaussianMixture(n_components = 4)\n",
    "\n",
    "## Fit the GMM on a single slice of the MRI data\n",
    "data = np_copy[middle_slice]\n",
    "gmm.fit(np.reshape(data, (data.size, 1)))\n",
    "\n",
    "## Classify the all images according to the GMM\n",
    "for j in range(2):\n",
    "    im = np_copy[j]\n",
    "    cls = gmm.predict(im.reshape((im.size, 1)))\n",
    "    seg = np.zeros(np_copy[0].shape)\n",
    "    seg = cls.reshape(np_copy[0].shape)\n",
    "    np_mask_copy[j] = seg\n",
    "\n",
    "## Copy of numpy.ndarray to itk.Image\n",
    "mask_itk = itk.image_from_array(np_mask_copy)\n",
    "\n",
    "## The conversion  itk -> numpy -> itk will change axis orientation. Correct it with the following filter\n",
    "flipFilter = itk.FlipImageFilter[itk.Image.SS3].New()\n",
    "flipFilter.SetInput(mask_itk)\n",
    "flipAxes = (False, True, False)\n",
    "flipFilter.SetFlipAxes(flipAxes)\n",
    "flipFilter.Update()\n",
    "\n",
    "corrected_mask = flipFilter.GetOutput()\n",
    "itkw.view(corrected_mask, cmap='Grayscale', mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save mask for next notebook on Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_filter = itk.ImageFileWriter[labelled_bayesian].New(labelled_bayesian)\n",
    "write_filter.SetFileName('bayesian_mask.nii.gz')\n",
    "write_filter.Update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
